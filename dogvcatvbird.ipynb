{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!! pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQiKrYPeHHV2",
        "outputId": "aae5d408-c56e-40fa-b012-595e9a903e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)',\n",
              " 'Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)',\n",
              " 'Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)',\n",
              " 'Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)',\n",
              " 'Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)',\n",
              " 'Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)',\n",
              " 'Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset/train.csv')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assume your DataFrame is named 'df' and has a column 'label' for class labels\n",
        "\n",
        "# Stratified sampling to retain class balance\n",
        "df_sampled, _ = train_test_split(df, test_size=0.70, stratify=df['label'], random_state=42)\n",
        "\n",
        "df = df_sampled\n",
        "\n",
        "############################################################\n",
        "#####   do this again for a smaller working dataset   ######\n",
        "############################################################\n",
        "df_sampled, _ = train_test_split(df, test_size=0.20, stratify=df['label'], random_state=42)\n",
        "\n",
        "\n",
        "df = df_sampled\n",
        "\n",
        "# Create a mapping from string labels to numerical indices\n",
        "class_mapping = {'dog': 0, 'cat': 1, 'bird': 2} #Example mapping, adjust if needed\n",
        "#Reverse mapping for later use\n",
        "reverse_mapping = {0: 'dog', 1: 'cat', 2: 'bird'}\n",
        "#Map the string labels to numerical indices in the dataframe\n",
        "df['label'] = df['label'].map(class_mapping)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def create_dataloaders(train_df, test_df, root_dir, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = CustomDataset(train_df, os.path.join(root_dir, 'train'), transform=transform)\n",
        "    test_dataset = CustomDataset(test_df, os.path.join(root_dir, 'train'), transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Define a simple CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 56 * 56)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Prepare the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = len(df['label'].unique())  # Assuming df contains your label data\n",
        "model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "## data loaders\n",
        "train_loader, test_loader = create_dataloaders(train_df, test_df, root_dir, batch_size)\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 30\n",
        "# Train the model (make sure to define train_loader and num_epochs)\n",
        "train_model(model, train_loader, criterion, optimizer, device, num_epochs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shh4HbCiq0sy",
        "outputId": "1794d0d9-f45a-4b6d-92a6-52fcaf0e4afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 4.9589, Accuracy: 34.38%\n",
            "Epoch 2/30, Loss: 1.0772, Accuracy: 42.71%\n",
            "Epoch 3/30, Loss: 1.0515, Accuracy: 42.36%\n",
            "Epoch 4/30, Loss: 1.0075, Accuracy: 46.53%\n",
            "Epoch 5/30, Loss: 0.9868, Accuracy: 48.61%\n",
            "Epoch 6/30, Loss: 0.8814, Accuracy: 57.29%\n",
            "Epoch 7/30, Loss: 0.8129, Accuracy: 65.28%\n",
            "Epoch 8/30, Loss: 0.7466, Accuracy: 68.06%\n",
            "Epoch 9/30, Loss: 0.6729, Accuracy: 68.40%\n",
            "Epoch 10/30, Loss: 0.5640, Accuracy: 77.78%\n",
            "Epoch 11/30, Loss: 0.4709, Accuracy: 82.64%\n",
            "Epoch 12/30, Loss: 0.3688, Accuracy: 88.54%\n",
            "Epoch 13/30, Loss: 0.2649, Accuracy: 90.62%\n",
            "Epoch 14/30, Loss: 0.2161, Accuracy: 93.40%\n",
            "Epoch 15/30, Loss: 0.1509, Accuracy: 94.79%\n",
            "Epoch 16/30, Loss: 0.1143, Accuracy: 97.57%\n",
            "Epoch 17/30, Loss: 0.0722, Accuracy: 98.96%\n",
            "Epoch 18/30, Loss: 0.0668, Accuracy: 98.61%\n",
            "Epoch 19/30, Loss: 0.0597, Accuracy: 98.26%\n",
            "Epoch 20/30, Loss: 0.0412, Accuracy: 98.96%\n",
            "Epoch 21/30, Loss: 0.1130, Accuracy: 96.53%\n",
            "Epoch 22/30, Loss: 0.0619, Accuracy: 98.61%\n",
            "Epoch 23/30, Loss: 0.0533, Accuracy: 98.61%\n",
            "Epoch 24/30, Loss: 0.0413, Accuracy: 98.61%\n",
            "Epoch 25/30, Loss: 0.0211, Accuracy: 99.65%\n",
            "Epoch 26/30, Loss: 0.0166, Accuracy: 100.00%\n",
            "Epoch 27/30, Loss: 0.0094, Accuracy: 100.00%\n",
            "Epoch 28/30, Loss: 0.0074, Accuracy: 100.00%\n",
            "Epoch 29/30, Loss: 0.0040, Accuracy: 100.00%\n",
            "Epoch 30/30, Loss: 0.0031, Accuracy: 100.00%\n",
            "Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Base CNN"
      ],
      "metadata": {
        "id": "fJdBcuCSsu4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, target_names=reverse_mapping.values())\n",
        "    print(report)\n",
        "\n",
        "\n",
        "print('----------------------------------')\n",
        "print('Evaluating Train data accuracy')\n",
        "print('----------------------------------')\n",
        "evaluate_model(model, train_loader, device)\n",
        "\n",
        "print('----------------------------------')\n",
        "print('Evaluating Test data accuracy')\n",
        "print('----------------------------------')\n",
        "evaluate_model(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "reJO-qSastu5",
        "outputId": "9fc86904-45d8-4215-e277-ba11fb41adea"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------\n",
            "Evaluating Train data accuracy\n",
            "----------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         dog       1.00      1.00      1.00        96\n",
            "         cat       1.00      1.00      1.00        96\n",
            "        bird       1.00      1.00      1.00        96\n",
            "\n",
            "    accuracy                           1.00       288\n",
            "   macro avg       1.00      1.00      1.00       288\n",
            "weighted avg       1.00      1.00      1.00       288\n",
            "\n",
            "----------------------------------\n",
            "Evaluating Test data accuracy\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-e18c790a1858>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluating Test data accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-100-e18c790a1858>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-b2e3643aeb94>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert label to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36mrealpath\u001b[0;34m(filename, strict)\u001b[0m\n\u001b[1;32m    394\u001b[0m symbolic links encountered in the path.\"\"\"\n\u001b[1;32m    395\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joinrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, strict, seen)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the basic functions for the project\n",
        "I've decied to use resnet18 for this assignment, completely missed the fact that I had to start with a baseline CNN.\n",
        "\n",
        "My initial attempts at this revolved aroung using a resnet18 that was not pretrained, and the best result I got was a whopping 54%\n",
        "\n",
        "Fortunately that wasn't necessary and I could use a pretrained version accoring to whoever I asked. Life-savers."
      ],
      "metadata": {
        "id": "6aJEkT8yg7rL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6mVvnl-GAAm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# 1. Function to split the dataset\n",
        "def split_data(df, test_size=0.90, random_state=42):\n",
        "    return train_test_split(df, test_size=test_size, stratify=df['label'], random_state=random_state)\n",
        "\n",
        "\n",
        "# 2. Custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        while True:\n",
        "            img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
        "            try:\n",
        "                image = Image.open(img_name).convert('RGB')\n",
        "                label = self.dataframe.iloc[idx, 1]\n",
        "                label = torch.tensor(label, dtype=torch.long)  # Convert label to tensor\n",
        "\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "\n",
        "                return image, label\n",
        "            except FileNotFoundError:\n",
        "                idx = (idx + 1) % len(self.dataframe)  # Wrap around index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3. Function to create dataloaders\n",
        "def create_dataloaders(train_df, test_df, root_dir, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = CustomDataset(train_df, os.path.join(root_dir, 'train'), transform=transform)\n",
        "    test_dataset = CustomDataset(test_df, os.path.join(root_dir, 'train'), transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# 4. Function to define and prepare the model\n",
        "def get_model(num_classes, device):\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = torch.nn.Linear(num_ftrs, num_classes)  # Adjust final layer\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients from the previous step\n",
        "            outputs = model(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute the loss\n",
        "            loss.backward()  # Backpropagate the gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            # Accumulate the loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Compute accuracy for this batch\n",
        "            _, preds = torch.max(outputs, 1)  # Get predicted class\n",
        "            correct_predictions += torch.sum(preds == labels).item()  # Count correct predictions\n",
        "            total_predictions += labels.size(0)  # Count total predictions\n",
        "\n",
        "        # Compute the loss and accuracy for the epoch\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "        # Print the loss and accuracy for the epoch\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%')\n",
        "\n",
        "    print('Training complete')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data\n",
        "\n",
        "Due to limited resources, I decided to use a smaller chunk of the data than what was provided. I figured, around 30% of the total should be enough\n",
        "\n",
        "Then split that again into 80% for training and 20% for testing\n",
        "\n",
        "I did make sure that the classes did not get imbalanced and hence the hack code below"
      ],
      "metadata": {
        "id": "qvPF5CLJh410"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dataset/train.csv')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assume your DataFrame is named 'df' and has a column 'label' for class labels\n",
        "\n",
        "# Stratified sampling to retain class balance\n",
        "df_sampled, _ = train_test_split(df, test_size=0.70, stratify=df['label'], random_state=42)\n",
        "\n",
        "# Display the sampled DataFrame\n",
        "print(df_sampled.head())\n",
        "\n",
        "# Verify the class distribution\n",
        "print(df_sampled['label'].value_counts(normalize=True))\n",
        "\n",
        "df = df_sampled\n",
        "\n",
        "############################################################\n",
        "#####   do this again for a smaller working dataset   ######\n",
        "############################################################\n",
        "df_sampled, _ = train_test_split(df, test_size=0.20, stratify=df['label'], random_state=42)\n",
        "\n",
        "# Display the sampled DataFrame\n",
        "print(df_sampled.head())\n",
        "\n",
        "# Verify the class distribution\n",
        "print(df_sampled['label'].value_counts(normalize=True))\n",
        "\n",
        "df = df_sampled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ARUULpHjQ-L",
        "outputId": "53f53628-5089-4bb4-da6b-65dac16adb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           filename label\n",
            "3903   cat_9975.png   cat\n",
            "7692  bird_6839.png  bird\n",
            "4443  dog_14123.png   dog\n",
            "9995  bird_2072.png  bird\n",
            "6974  bird_3200.png  bird\n",
            "label\n",
            "cat     0.333333\n",
            "bird    0.333333\n",
            "dog     0.333333\n",
            "Name: proportion, dtype: float64\n",
            "            filename label\n",
            "6635    dog_5200.png   dog\n",
            "11768   bird_112.png  bird\n",
            "11057    dog_255.png   dog\n",
            "4358     dog_194.png   dog\n",
            "11773  cat_12188.png   cat\n",
            "label\n",
            "dog     0.333333\n",
            "bird    0.333333\n",
            "cat     0.333333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Model\n",
        "\n",
        "To make sure the data trained was generalisable, I kept the Epoch at 30, which has the best results I believe, they're not very overfit.\n"
      ],
      "metadata": {
        "id": "SpXgyvHii5UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from string labels to numerical indices\n",
        "class_mapping = {'dog': 0, 'cat': 1, 'bird': 2}\n",
        "#Reverse mapping for later use\n",
        "reverse_mapping = {0: 'dog', 1: 'cat', 2: 'bird'}\n",
        "#Map the string labels to numerical indices in the dataframe\n",
        "df['label'] = df['label'].map(class_mapping)\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/dataset'\n",
        "num_epochs=30\n",
        "batch_size=32\n",
        "\n",
        "# 6. Main function to orchestrate everything\n",
        "#def main(df, root_dir, num_epochs=10, batch_size=32):\n",
        "# Split the data\n",
        "train_df, test_df = split_data(df)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader, test_loader = create_dataloaders(train_df, test_df, root_dir, batch_size)\n",
        "\n",
        "# Prepare the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = len(df['label'].unique())\n",
        "model = get_model(num_classes, device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, device, num_epochs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s45CiWh9HCR5",
        "outputId": "a4da2ba5-0293-451d-b89c-68a886202514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 0.9223, Accuracy: 52.08%\n",
            "Epoch 2/30, Loss: 0.2276, Accuracy: 96.18%\n",
            "Epoch 3/30, Loss: 0.0649, Accuracy: 100.00%\n",
            "Epoch 4/30, Loss: 0.0268, Accuracy: 100.00%\n",
            "Epoch 5/30, Loss: 0.0103, Accuracy: 100.00%\n",
            "Epoch 6/30, Loss: 0.0095, Accuracy: 100.00%\n",
            "Epoch 7/30, Loss: 0.0088, Accuracy: 100.00%\n",
            "Epoch 8/30, Loss: 0.0053, Accuracy: 100.00%\n",
            "Epoch 9/30, Loss: 0.0035, Accuracy: 100.00%\n",
            "Epoch 10/30, Loss: 0.0041, Accuracy: 100.00%\n",
            "Epoch 11/30, Loss: 0.0027, Accuracy: 100.00%\n",
            "Epoch 12/30, Loss: 0.0025, Accuracy: 100.00%\n",
            "Epoch 13/30, Loss: 0.0031, Accuracy: 100.00%\n",
            "Epoch 14/30, Loss: 0.0034, Accuracy: 100.00%\n",
            "Epoch 15/30, Loss: 0.0023, Accuracy: 100.00%\n",
            "Epoch 16/30, Loss: 0.0019, Accuracy: 100.00%\n",
            "Epoch 17/30, Loss: 0.0020, Accuracy: 100.00%\n",
            "Epoch 18/30, Loss: 0.0038, Accuracy: 100.00%\n",
            "Epoch 19/30, Loss: 0.0015, Accuracy: 100.00%\n",
            "Epoch 20/30, Loss: 0.0017, Accuracy: 100.00%\n",
            "Epoch 21/30, Loss: 0.0014, Accuracy: 100.00%\n",
            "Epoch 22/30, Loss: 0.0020, Accuracy: 100.00%\n",
            "Epoch 23/30, Loss: 0.0013, Accuracy: 100.00%\n",
            "Epoch 24/30, Loss: 0.0010, Accuracy: 100.00%\n",
            "Epoch 25/30, Loss: 0.0011, Accuracy: 100.00%\n",
            "Epoch 26/30, Loss: 0.0010, Accuracy: 100.00%\n",
            "Epoch 27/30, Loss: 0.0023, Accuracy: 100.00%\n",
            "Epoch 28/30, Loss: 0.0007, Accuracy: 100.00%\n",
            "Epoch 29/30, Loss: 0.0012, Accuracy: 100.00%\n",
            "Epoch 30/30, Loss: 0.0017, Accuracy: 100.00%\n",
            "Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking accuracy based on test data\n"
      ],
      "metadata": {
        "id": "gIn_C7LMjONL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Function to evaluate the model on the test set\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')  # Macro recall\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')  # Macro F1-score\n",
        "    class_report = classification_report(all_labels, all_preds, target_names=['bird', 'cat', 'dog'])\n",
        "\n",
        "    return accuracy, recall, f1, class_report\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy, recall, f1, class_report = evaluate_model(model, train_loader, device)\n",
        "print('----------------------------------')\n",
        "print('Evaluating Train data accuracy')\n",
        "print('----------------------------------')\n",
        "# Print the results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n",
        "print('Classification Report:')\n",
        "print(class_report)\n",
        "\n",
        "print('----------------------------------')\n",
        "print('Evaluating Test data accuracy')\n",
        "print('----------------------------------')\n",
        "# Evaluate the model\n",
        "accuracy, recall, f1, class_report = evaluate_model(model, test_loader, device)\n",
        "\n",
        "# Print the results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n",
        "print('Classification Report:')\n",
        "print(class_report)\n",
        "\n",
        "# Optionally, map the numeric labels back to the class names for display\n",
        "reverse_mapping = {0: 'dog', 1: 'cat', 2: 'bird'}\n",
        "test_df['label'] = test_df['label'].map(reverse_mapping)\n",
        "#print(test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQTPBSYFYdIX",
        "outputId": "b3bd5752-84f6-4777-82bf-2f5cef58fea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "Evaluating Train data accuracy\n",
            "----------------------------------\n",
            "Accuracy: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bird       1.00      1.00      1.00        96\n",
            "         cat       1.00      1.00      1.00        96\n",
            "         dog       1.00      1.00      1.00        96\n",
            "\n",
            "    accuracy                           1.00       288\n",
            "   macro avg       1.00      1.00      1.00       288\n",
            "weighted avg       1.00      1.00      1.00       288\n",
            "\n",
            "----------------------------------\n",
            "Evaluating Test data accuracy\n",
            "----------------------------------\n",
            "Accuracy: 0.8152\n",
            "Recall: 0.8152\n",
            "F1-Score: 0.8144\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bird       0.80      0.77      0.79       864\n",
            "         cat       0.77      0.76      0.76       864\n",
            "         dog       0.87      0.91      0.89       864\n",
            "\n",
            "    accuracy                           0.82      2592\n",
            "   macro avg       0.81      0.82      0.81      2592\n",
            "weighted avg       0.81      0.82      0.81      2592\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looks good to me"
      ],
      "metadata": {
        "id": "run3g1ACjVFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now for the main objective the 3000 imges of test"
      ],
      "metadata": {
        "id": "LznwFVTDjYf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "root_dir = '/content/drive/MyDrive/dataset'\n",
        "# Get the list of image filenames in the 'test' folder\n",
        "test_folder = rf'{root_dir}/test'\n",
        "test_filenames = [f for f in os.listdir(test_folder) if os.path.isfile(os.path.join(test_folder, f))]\n",
        "\n",
        "# Create a dataframe with the filenames\n",
        "test_df = pd.DataFrame(test_filenames, columns=['file_name'])\n",
        "print(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eey5RhcaILQi",
        "outputId": "8eaa24cf-243b-4de7-e57e-180d5d6af298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         file_name\n",
            "0     img_2614.png\n",
            "1        img_3.png\n",
            "2      img_241.png\n",
            "3     img_2338.png\n",
            "4     img_2346.png\n",
            "...            ...\n",
            "3015  img_1233.png\n",
            "3016  img_1084.png\n",
            "3017  img_1093.png\n",
            "3018  img_1181.png\n",
            "3019  img_1059.png\n",
            "\n",
            "[3020 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_labels(model, test_df, root_dir, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(len(test_df)):\n",
        "            img_name = os.path.join(root_dir, 'test', test_df.iloc[idx, 0])\n",
        "            try:\n",
        "                image = Image.open(img_name).convert('RGB')\n",
        "                image = transform(image).unsqueeze(0).to(device)\n",
        "                outputs = model(image)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.append(predicted.item())\n",
        "            except FileNotFoundError:\n",
        "                predictions.append(None)  # If file is not found, append None\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Run predictions and save them in test_df\n",
        "test_df['label'] = predict_labels(model, test_df, root_dir, device)\n",
        "print(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHfkhGxBhlu3",
        "outputId": "378e30d0-5e63-4354-e37d-efbf12ea1a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         file_name  label\n",
            "0     img_2614.png      1\n",
            "1        img_3.png      1\n",
            "2      img_241.png      2\n",
            "3     img_2338.png      0\n",
            "4     img_2346.png      0\n",
            "...            ...    ...\n",
            "3015  img_1233.png      0\n",
            "3016  img_1084.png      1\n",
            "3017  img_1093.png      2\n",
            "3018  img_1181.png      0\n",
            "3019  img_1059.png      0\n",
            "\n",
            "[3020 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_mapping = {0: 'dog', 1: 'cat', 2: 'bird'}\n",
        "test_df['label'] = test_df['label'].map(reverse_mapping)\n",
        "print(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mby73y6oXk4F",
        "outputId": "31d01fe5-d3aa-488a-cb59-360729df8390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         file_name label\n",
            "0     img_2614.png   cat\n",
            "1        img_3.png   cat\n",
            "2      img_241.png  bird\n",
            "3     img_2338.png   dog\n",
            "4     img_2346.png   dog\n",
            "...            ...   ...\n",
            "3015  img_1233.png   dog\n",
            "3016  img_1084.png   cat\n",
            "3017  img_1093.png  bird\n",
            "3018  img_1181.png   dog\n",
            "3019  img_1059.png   dog\n",
            "\n",
            "[3020 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('results.csv')"
      ],
      "metadata": {
        "id": "vVXF_AvNXmMU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}